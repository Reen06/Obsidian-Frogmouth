
## **Purpose of Create Video**

- Takes **decoded image frames** generated by your model and compiles them into a video file.
    
- Lets you set:
    
    - **Frame rate (fps)** – how fast frames play back.
        
    - Optional **audio track** – if you want sound included.
        
- Outputs a single **VIDEO file** that you can save or preview.
    

Think of it as the final render step in your pipeline.

---

## **Inputs**

### **1. images (Blue Input - Frame Sequence)**

- The sequence of decoded images that will make up your video.
    
- Typically comes directly from **VAE Decode**, which converts the model’s latent frames into actual pixel frames.
    

**Example connection:**

```
KSampler (Advanced) → VAE Decode → Create Video
```

---

### **2. audio (Gray Input - Optional)**

- An optional audio file or track to embed into your generated video.
    
- If left empty, the video will be **silent**.
    
- Useful for syncing generated clips with:
    
    - Background music.
        
    - Narration.
        
    - Sound effects.
        

> **Note:**  
> The audio track must match the video’s timing. If your video is shorter or longer than the audio file, you may need to edit or sync it beforehand.

---

## **Parameter**

### **fps (Frames Per Second)**

- Determines how many frames are shown each second in the final video.
    
- The fps setting directly affects:
    
    - **Playback speed**
        
    - **Smoothness**
        
    - **Video duration**
        

**How it works:**

- **Video length (seconds)** = Total frames ÷ FPS
    

|FPS|Look & Feel|Example Use|
|---|---|---|
|**12**|Choppy, stop-motion style|Animations, previews|
|**16**|Smooth but lightweight|General test videos (default)|
|**24**|Standard cinematic smoothness|Movies, realistic motion|
|**30+**|Ultra-smooth, high realism|Gaming or slow-motion effects|

**Example Calculation:**  
If you generated 81 frames at **16 fps**:

```
81 frames ÷ 16 fps = ~5.06 seconds
```

---

## **Output**

### **VIDEO (Green Output)**

- The final compiled video file.
    
- You can:
    
    - Preview it directly in ComfyUI (if supported).
        
    - Save it to disk as `.mp4` or `.webm`.
        
    - Import into editing software for further refinement.
        

---

## **Typical Workflow Placement**

Here’s how it fits into your complete WAN 2.2 video generation pipeline:

```
Load CLIP → CLIP Text Encode (Positive / Negative Prompts)

EmptyHunyuanLatentVideo → KSampler (Advanced) → VAE Decode → Create Video → Save Video

Load Diffusion Model → LoraLoaderModelOnly → ModelSamplingSD3 → KSampler (Advanced)

Load VAE → VAE Decode
```

The simplified data flow looks like this:

```
Latents → [KSampler] → Decoded Frames → [Create Video] → Final Video
```

---

## **Best Practices**

### **1. Choosing FPS**

- Start with **16 fps** (the default) for testing.
    
- For smoother motion:
    
    - Increase to **24 fps** or **30 fps**.
        
    - Keep in mind that higher fps = more frames needed for the same clip length.
        

### **2. Matching Frame Count and FPS**

- Decide how long you want the video to be **before generating frames**.
    
- Use the formula:
    
    ```
    Total Frames = Desired Video Length (sec) × FPS
    ```
    
    Example:  
    For a 3-second clip at 24 fps:
    
    ```
    3 × 24 = 72 frames
    ```
    

### **3. Adding Audio**

- If you want music or sound effects:
    
    - Make sure the audio file is trimmed to match your video length.
        
    - Otherwise, the video might cut off early or have silence at the end.
        

---

## **Example Configurations**

|Goal|FPS|Frames Needed|Duration|
|---|---|---|---|
|Quick preview clip|12|36|3 sec|
|Standard smooth video|16|48|3 sec|
|Cinematic look|24|72|3 sec|
|Ultra-smooth motion|30|90|3 sec|

---

## **Summary Table**

|Input / Output|Description|Example Source|
|---|---|---|
|**images (Blue)**|Frame sequence to compile into video|VAE Decode|
|**audio (Gray)**|Optional audio track for final video|External audio file|
|**fps**|Frames per second for playback speed|16 (default)|
|**VIDEO (Green)**|Final compiled video output|Save Video node|

---

## **Final Example Workflow**

Here’s a complete flow for text-to-video using your WAN 2.2 setup:

```
Text Prompts → CLIP Text Encode → KSampler (Advanced) → VAE Decode → Create Video → Save Video
```

Expanded with all your nodes:

```
Load CLIP
Load Diffusion Model → LoraLoaderModelOnly → ModelSamplingSD3 → KSampler (Advanced)
EmptyHunyuanLatentVideo → KSampler (Advanced)
Load VAE → VAE Decode
VAE Decode → Create Video → Save Video
```

This ensures that your pipeline:

1. Generates a sequence of latent frames.
    
2. Decodes them into pixel-space images.
    
3. Compiles them into a smooth, playable video.
    
